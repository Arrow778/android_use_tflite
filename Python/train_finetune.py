import os
import tensorflow as tf
from tensorflow.keras import layers, models, applications, regularizers
import matplotlib.pyplot as plt
import os.path as path
from datetime import datetime
import numpy as np

# ======================
# 1. å…¨å±€é…ç½®
# ======================
CONFIG = {
    # è·¯å¾„é…ç½®
    "DATASET_PATH": "datasets/train_1",  # ä½ çš„æ•°æ®é›†è·¯å¾„
    "MODEL_DIR_ROOT": "models",  # æ¨¡å‹ä¿å­˜ç›®å½•
    "LABEL_DIR_ROOT": "labels",  # æ ‡ç­¾ä¿å­˜ç›®å½•

    # è®­ç»ƒå‚æ•°
    "IMG_SIZE": (224, 224),
    "BATCH_SIZE": 32,  # å¦‚æœæ˜¾å­˜ > 4GBæˆ–è€…æ•°æ®é‡å°ï¼Œå»ºè®®æ”¹ä¸º 32
    "EPOCHS": 15,  # å•é˜¶æ®µæœ€å¤§è½®æ•° (é…åˆæ—©åœï¼Œä¸ç”¨æ‹…å¿ƒè¿‡å¤š)
    "LEARNING_RATE": 1e-3,  # åˆå§‹å­¦ä¹ ç‡ 0.001
    "SEED": 100,
    "VAL_RATE": 0.30,  # éªŒè¯é›†æ¯”ä¾‹
}


# ======================
# 2. å·¥å…·å‡½æ•°
# ======================
def ensure_dirs_exist():
    """åˆ›å»ºå¿…è¦çš„æ–‡ä»¶å¤¹"""
    for d in [CONFIG["MODEL_DIR_ROOT"], CONFIG["LABEL_DIR_ROOT"]]:
        if not path.exists(d):
            os.makedirs(d)
            print(f"ğŸ“‚ Created directory: {d}")


def setup_gpu():
    """é…ç½®æ˜¾å­˜æŒ‰éœ€å¢é•¿"""
    gpus = tf.config.list_physical_devices('GPU')
    if gpus:
        try:
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
            print(f"âœ… GPU Ready: {len(gpus)} device(s)")
        except RuntimeError as e:
            print(e)
    else:
        print("âš ï¸ No GPU found. Training will be slow.")


def calculate_class_weights(data_path):
    """è®¡ç®—ç±»åˆ«æƒé‡ï¼Œå¤„ç†æ ·æœ¬ä¸å¹³è¡¡"""
    counts = {}
    class_names = sorted([d for d in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, d))])

    total = 0
    for idx, name in enumerate(class_names):
        p = os.path.join(data_path, name)
        # åªç»Ÿè®¡å›¾ç‰‡æ–‡ä»¶
        c = len([f for f in os.listdir(p) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))])
        counts[idx] = c
        total += c

    num_classes = len(class_names)
    weights = {}
    if num_classes > 0:
        for idx, count in counts.items():
            if count > 0:
                weights[idx] = (1.0 / count) * (total / num_classes)
            else:
                weights[idx] = 1.0

    print(f"ğŸ“Š Class Weights calculated. Total images: {total}")
    return weights, num_classes, class_names


def load_datasets(data_path, img_size, batch_size, seed, val_rate):
    """åŠ è½½æ•°æ®ç®¡çº¿"""
    print("ğŸ”„ Loading datasets...")
    train_ds = tf.keras.utils.image_dataset_from_directory(
        data_path, validation_split=val_rate, subset="training",
        seed=seed, image_size=img_size, batch_size=batch_size,
        label_mode="categorical", shuffle=True
    )
    val_ds = tf.keras.utils.image_dataset_from_directory(
        data_path, validation_split=val_rate, subset="validation",
        seed=seed, image_size=img_size, batch_size=batch_size,
        label_mode="categorical", shuffle=True
    )

    # æ€§èƒ½ä¼˜åŒ–ï¼šç¼“å­˜å’Œé¢„å–
    AUTOTUNE = tf.data.AUTOTUNE
    train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)
    val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)
    return train_ds, val_ds


# ======================
# 3. æ¨¡å‹æ„å»º
# ======================
def build_model_graph(num_classes, img_size):
    """
    æ„å»ºæ¨¡å‹ï¼šåŒ…å«æ•°æ®å¢å¼ºå’Œé¢„è®­ç»ƒçš„ MobileNetV2
    """
    # 1. å¼ºåŠ›æ•°æ®å¢å¼º (è®­ç»ƒæ—¶å¼€å¯ï¼Œé¢„æµ‹æ—¶è‡ªåŠ¨å…³é—­)
    data_augmentation = tf.keras.Sequential([
        layers.RandomFlip("horizontal"),
        layers.RandomRotation(0.2),
        layers.RandomZoom(0.2),
        layers.RandomContrast(0.1),
        layers.RandomTranslation(0.1, 0.1)
    ], name="data_augmentation")

    # 2. é¢„å¤„ç†
    preprocess_input = applications.mobilenet_v2.preprocess_input

    # 3. åŸºç¡€æ¨¡å‹ (ä¸å«é¡¶å±‚ï¼Œä½¿ç”¨ ImageNet æƒé‡)
    base_model = applications.MobileNetV2(
        input_shape=(*img_size, 3),
        include_top=False,
        weights="imagenet"
    )

    # ğŸ§Š å…³é”®ï¼šå†»ç»“åŸºç¡€æ¨¡å‹ï¼Œåªè®­ç»ƒæ–°åŠ çš„å±‚
    base_model.trainable = False

    # 4. ç»„è£…
    inputs = tf.keras.Input(shape=(*img_size, 3))
    x = data_augmentation(inputs)
    x = layers.Lambda(preprocess_input)(x)

    # training=False ç¡®ä¿ BN å±‚ä½¿ç”¨ ImageNet çš„ç»Ÿè®¡æ•°æ®ï¼Œè€Œä¸æ˜¯å½“å‰ Batch çš„
    # è¿™å¯¹è¿ç§»å­¦ä¹ éå¸¸é‡è¦ï¼Œèƒ½ä¿è¯ç¨³å®šæ€§
    x = base_model(x, training=False)

    x = layers.GlobalAveragePooling2D()(x)
    x = layers.BatchNormalization()(x)
    x = layers.Dropout(0.4)(x)  # é˜²æ­¢è¿‡æ‹Ÿåˆ

    outputs = layers.Dense(
        num_classes,
        activation="softmax",
        kernel_regularizer=regularizers.l2(1e-4)  # è½»å¾®çš„æ­£åˆ™åŒ–
    )(x)

    model = tf.keras.Model(inputs, outputs)
    return model


# ======================
# 4. å¯è§†åŒ–ä¸ä¿å­˜
# ======================
def plot_history(history, save_path):
    """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
    acc = history.history['accuracy']
    val_acc = history.history['val_accuracy']
    loss = history.history['loss']
    val_loss = history.history['val_loss']
    epochs_range = range(len(acc))

    plt.figure(figsize=(12, 6))

    # å‡†ç¡®ç‡
    plt.subplot(1, 2, 1)
    plt.plot(epochs_range, acc, label='Training Accuracy')
    plt.plot(epochs_range, val_acc, label='Validation Accuracy')
    plt.legend(loc='lower right')
    plt.title('Training and Validation Accuracy')

    # æŸå¤±
    plt.subplot(1, 2, 2)
    plt.plot(epochs_range, loss, label='Training Loss')
    plt.plot(epochs_range, val_loss, label='Validation Loss')
    plt.legend(loc='upper right')
    plt.title('Training and Validation Loss')

    plt.savefig(save_path)
    print(f"ğŸ“ˆ Training curve saved to {save_path}")


def save_tflite(model, save_path):
    """è½¬æ¢ä¸º TFLite (float16 é‡åŒ–)"""
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.target_spec.supported_types = [tf.float16]  # åŠç²¾åº¦é‡åŒ–ï¼Œå‡å°ä½“ç§¯
    tflite_model = converter.convert()

    with open(save_path, 'wb') as f:
        f.write(tflite_model)
    print(f"ğŸ’¾ TFLite model saved: {save_path}")


def save_labels(names, save_path):
    """ä¿å­˜æ ‡ç­¾æ–‡ä»¶"""
    with open(save_path, 'w', encoding='utf-8') as f:
        for n in names:
            f.write(n + '\n')
    print(f"ğŸ·ï¸ Labels saved: {save_path}")


# ======================
# 5. ä¸»ç¨‹åº
# ======================
def main():
    ensure_dirs_exist()
    setup_gpu()

    # 1. å‡†å¤‡æ•°æ®
    weights, num_classes, class_names = calculate_class_weights(CONFIG["DATASET_PATH"])
    train_ds, val_ds = load_datasets(
        CONFIG["DATASET_PATH"], CONFIG["IMG_SIZE"], CONFIG["BATCH_SIZE"],
        CONFIG["SEED"], CONFIG["VAL_RATE"]
    )

    # 2. æ„å»ºæ¨¡å‹
    print("\nğŸ”¨ Building Model...")
    model = build_model_graph(num_classes, CONFIG["IMG_SIZE"])
    model.summary()

    # 3. ç¼–è¯‘æ¨¡å‹
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=CONFIG["LEARNING_RATE"]),
        loss="categorical_crossentropy",
        metrics=["accuracy"]
    )

    # 4. å®šä¹‰å›è°ƒå‡½æ•° (è®©è®­ç»ƒæ›´æ™ºèƒ½)
    callbacks = [
        # å¦‚æœéªŒè¯é›† Loss 3è½®ä¸ä¸‹é™ï¼Œè‡ªåŠ¨å‡å°å­¦ä¹ ç‡
        tf.keras.callbacks.ReduceLROnPlateau(
            monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-6
        ),
        # å¦‚æœéªŒè¯é›† Accuracy 6è½®ä¸æå‡ï¼Œæå‰ç»“æŸ
        tf.keras.callbacks.EarlyStopping(
            monitor='val_accuracy', patience=6, restore_best_weights=True, verbose=1
        )
    ]

    # 5. å¼€å§‹è®­ç»ƒ (å•é˜¶æ®µ)
    print(f"\nğŸš€ Starting Training for {CONFIG['EPOCHS']} epochs...")
    history = model.fit(
        train_ds,
        epochs=CONFIG["EPOCHS"],
        validation_data=val_ds,
        class_weight=weights,
        callbacks=callbacks
    )

    # ==========================
    # æ”¶å°¾å·¥ä½œ
    # ==========================
    timestamp = datetime.now().strftime('%m-%d-%H-%M')

    # ç»˜å›¾
    plot_history(history, "img\\training_curve_final.png")

    # ä¿å­˜ TFLite
    # æ³¨æ„ï¼šTFLite Converter ä¼šè‡ªåŠ¨å¿½ç•¥è®­ç»ƒä¸“ç”¨çš„å±‚ï¼ˆå¦‚ Dropout å’Œ RandomFlipï¼‰
    print("\nğŸ“¦ Exporting TFLite model...")
    tflite_path = path.join(CONFIG["MODEL_DIR_ROOT"], f"model-final-{timestamp}.tflite")
    save_tflite(model, tflite_path)

    # ä¿å­˜æ ‡ç­¾
    label_path = path.join(CONFIG["LABEL_DIR_ROOT"], "label-mutil.txt")
    save_labels(class_names, label_path)

    print(f"\nâœ… All Done! éªŒè¯é›†å‡†ç¡®ç‡ (Best): {max(history.history['val_accuracy']):.4f}")


if __name__ == "__main__":
    main()